# 03.Improving the scraper

This article is part of a series that goes through all the steps needed to write a script that automatically scrapes information from a website. Other articles in this series so far covered:

*  [00.Pre-requisites](00.Pre-requisites.md)
*  [01.Introduction to Python scraping](01.PythonScraping.md)
*  [02.A Selenium scraper for TripAdvisor reviews](02.ScrapingTripAdvisor.md)

This final article will focus on how to improve the first versions of the scraper script by addressing its limitations.

## Functional limitations

### Getting reviews written in all languages
By default, TripAdvisor only shows English reviews. To view all languages, one needs to click _All languages_ and wait for the JavaScript to download the other reviews. The relevant HTML parts are shown below:

```html
<div class="item" data-value="ALL" data-tracker="All languages">
  <label for="filters_detail_language_filterLang_ALL" class="label container cx_brand_refresh_phase2">
    <!-- All Languages radio button -->
    <input id="filters_detail_language_filterLang_ALL" type="radio" name="filters_detail_language_filterLang_0" 
           value="ALL" onchange=" .. JavaScript ..">
    <span class="checkmark"></span>
    All languages
  </label>
</div>
<div class="item" data-value="en" data-tracker="English"> .. </div>
<div class="item" data-value="it" data-tracker="Italian"> .. </div>
<div class="item" data-value="fr" data-tracker="French"> .. </div>
```

The following Python code clicks the radio button to view reviews in all languages:

```python
# Get reviews in all languages
all_langs = driver.find_element_by_id("filters_detail_language_filterLang_ALL")
all_langs.click()
```

### Going through all the pages
Every restaurant will have a different number of reviews; hence we cannot assume how many pages there are. The scraper needs to look for the last page and go through them all one by one. From the HTML code below one can see that the last page link uses specific CSS classes ```pageNum last``` and has an attribute ```data-page-number``` with a value indicating the number of pages:

```html
<div class="pageNumbers">
	<a data-page-number="1" .. >1</a>
	<a data-page-number="2" .. >2</a>
	<a data-page-number="3" .. >3</a>
    ..
	<a class="separator cx_brand_refresh_phase2">â€¦</a>
    <!-- Link to the last page -->
	<a data-page-number="41" data-offset="400" class="pageNum last cx_brand_refresh_phase2" .. >41</a>
</div>
```

The following code gets the number of pages, and stores it in an int value to be used in a loop:

```python
# Find the last page number
last_page = driver.find_element_by_xpath(".//a[contains(@class, 'pageNum last')]");
pages = last_page.get_attribute("data-page-number")
for p in range(pages): 
  # code here
```

### Reading all the reviews in one page

## Script improvements

### Exception handling

### Waits
While using ```time.sleep()``` to pause the script execution for a number of seconds until a page loads gets the job done it is not considered good practice. If the number of seconds is too small there is the risk that the loading is not ready yet, while if the scripts sleeps for too long it will degrade the performance of the scraper. Selenium offer a solution to this in the form of implicit and explicit waits.

When using **implicit waits**, the WebDriver will poll the HTML document a number of times when an element is not immediately available. By default, implicit waits are disabled, but they can go a long way in making our scraper less brittle. To enable implicit waits, the following line of code is added after creating the driver:

```python
driver.implicitly_wait(10)  # implicitly wait 10 seconds

```

Occasionally the scraper needs to wait for something very specific to happen. This is the case when having to wait for the loading DIV ```id=taplc_hotels_loading_box_rr_resp_0``` to disappear after clicking _All languages_. The code below achieves this using **explicit waits**:

```python
# Wait for reviews to load
WebDriverWait(driver, 30).until(
	EC.invisibility_of_element_located((By.ID, "taplc_hotels_loading_box_rr_resp_0"))
)
```

### General script maintainability and efficiency

All the locators has been moved out of the code and declared on top as 'constants'. This makes the code more readable, enables reusability and makes future maintanance easier. One could also consider the [Page Object Model](https://selenium-python.readthedocs.io/page-objects.html) but that would be beyond the scope of this article. As can be seen below, the use of XPath locators has been minimised:

```python
LOADING_DIV = (By.ID, "taplc_hotels_loading_box_rr_resp_0")
ALL_LANGS = (By.ID, "filters_detail_language_filterLang_ALL")
MORE_BTN = (By.CSS_SELECTOR, "span.taLnk.ulBlueLinks")
NEXT_BTN = (By.CSS_SELECTOR, 'a.nav.next')
LAST_PAGE = (By.CSS_SELECTOR, 'a.pageNum.last')
REVIEWS = (By.CSS_SELECTOR, 'div.ui_column.is-9')
SCORE = (By.XPATH, ".//span[contains(@class, 'ui_bubble_rating bubble_')]")
DATE = (By.CSS_SELECTOR, 'span.ratingDate')
TITLE = (By.CSS_SELECTOR, 'span.noQuotes')
REVIEW_TEXT = (By.CSS_SELECTOR, 'p.partial_entry')
```