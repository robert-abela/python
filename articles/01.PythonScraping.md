<!-- 
https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet
https://www.accordbox.com/blog/web-scraping-framework-review-scrapy-vs-selenium/
-->
# 01.Introduction to scraping
In this series of articles will go through all the steps needed to write a script that reads information from a website. Other articles in this series will cover:
* [00.Pre-requisites](00.Pre-requisites.md)
* [02.Writing a basic selenium script to get information](02.BasicSelenium.md)
* [03.Optimising the script for performance and stability](03.Optimisations.md)

This article introduces Selenium and a scraper (BeautifulSoup) detailing the process for their installation. It also discusses the difference between a simple scraper and using Selenium.

## Installing Selenium and other requirements
Selenium setup requires two steps:
1. install the Selenium library using the command: __pip install selenium__
1. download the Selenium WebDriver for your browser (exact version). Chrome drivers can be found on [chromium.org](https://chromedriver.chromium.org/downloads)
f
Scraper setup requires two command:
1. __pip install requests__ 
2. __pip install beautifulsoup4__

## Scraping a website
### What is web scraping?
Scraping is like browsing to a website and copying some content, but it is done programmatically (e.g. using Python) which means that it is much faster. The limit to how fast you can srape is basically your bandwith and computing power (and also how much the web server alows you to). Technically this process can be divided in two parts:
1. __Crawling__ is the first part, which basically involves opening a page and finding all the interesting links in it, e.g. shops listed in a section of the yellow pages. 
1. __Scraping__ comes next, where all the links from the previous step are visited to extract specific parts of the web page (e.g. the address or phone number).

### Challenges of Scraping
One main challenge is that websites tend to be varied and you will likely end up writing a scraper specific to the site you are dealing with. Even if you are dealing with the same websites, updates/re-designs will likely break your scraper in some way (you will be using the F12 button frequently). 

Some websites do not like to be scraped and will employ different techniques to slow or stop scraping. Another aspect to consider is the legality of this process, which depends on where the server is located, the term of service and what you do once you have the data amongst other things.

An Alternative to web scraping, when available, are Application Programming Interfaces (APIs) since they offer a way to access structured data directly (using formats like JSON and XML, without dealing with the visual presentation of the web pages. So it is always a good idea to check if the website ofers an API before investing time and effort in a scraper.

### Scraping libraries
While there are many ways how to get data from web pages (e.g. using Excel, browser plugins or other tools) this article will focus on how to do it with Python. Having the fleibility of a programming language makes it a very powerful approach and there are very good libraries available such as [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) which will be used in the sample below. There is a very good write up on how to [Build a Web Scraper With BeautifulSoup](https://realpython.com/beautiful-soup-web-scraper-python/). [Scrapy](https://scrapy.org/) is onother framework to consider.

### What is Selenium?
[Selenium](https://www.selenium.dev/) is a framework designed primarily for automated web applications testing. It allows developers to programatically control a browsers using different programming languages. 

Why is Selenium different?

### Basic scraper
```python
import requests
from bs4 import BeautifulSoup

#Visit Page and parse source HTML
page = requests.get("http://www.python.org")
soup = BeautifulSoup(page.content, 'html.parser')

#Check title is as expected
assert "Python" in soup.title.string

##Perform the search using HTTP GET request
page = requests.get( "https://www.python.org/search/?q=pip&submit=")
soup = BeautifulSoup(page.content, 'html.parser')

#Look for expected result is present
link = soup.find('a', href="/dev/peps/pep-0439/")
assert "PEP 439" in link.string
```
### Scraper using Selenium
```python
from selenium import webdriver

#Open browser and visit page
driver = webdriver.Chrome()
driver.get("http://www.python.org")

#Check title is as expected
assert "Python" in driver.title

#Find search field
search_field = driver.find_element_by_id("id-search-field")
#Enter search term
search_field.send_keys("pip")
#Find and click the Search button
search_button = driver.find_element_by_id("submit")
search_button.click()

#Look for expected result
link = driver.find_element_by_partial_link_text("PEP 439")
#Check the link is correct
assert link.get_attribute("href") == "https://www.python.org/dev/peps/pep-0439/"

#Close browser
driver.close()
```
