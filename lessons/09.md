# Lesson 9: Web scraping

## Installing the requirements

Scraper setup requires two commands:

1.  __pip install requests__
1.  __pip install beautifulsoup4__

## Scraping a website
### What is web scraping?
Scraping is like browsing to a website and copying some content, but it is done programmatically (e.g. using Python) which means that it is much faster. The limit to how fast you can scrape is basically your bandwidth and computing power (and how much the web server allows you to). Technically this process can be divided in two parts:

1.  __Crawling__ is the first part, which basically involves opening a page and finding all the interesting links in it, e.g. shops listed in a section of the yellow pages. 
2.  __Scraping__ comes next, where all the links from the previous step are visited to extract specific parts of the web page, e.g. the address or phone number.

### Challenges of Scraping
One main challenge is that websites tend to be varied and you will likely end up writing a scraper specific to every site you are dealing with. Even if you stick with the same websites, updates/re-designs will likely break your scraper in some way (you will be using the F12 button frequently). 

Some websites do not tolerate being scraped and will employ different techniques to slow or stop scraping. Another aspect to consider is the legality of this process, which depends on where the server is located, the term of service and what you do once you have the data amongst other things.

An Alternative to web scraping, when available, are Application Programming Interfaces (APIs) which offer a way to access structured data directly (using formats like JSON and XML) without dealing with the visual presentation of the web pages. Hence it is always a good idea to check if the website offers an API before investing time and effort in a scraper.

### Scraping libraries
While there are many ways how to get data from web pages (e.g. using Excel, browser plugins or other tools) this article will focus on how to do it with Python. Having the flexibility of a programming language makes it a very powerful approach and there are very good libraries available such as [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) which will be used in the sample below. There is a very good write up on how to [Build a Web Scraper With Beautiful Soup](https://realpython.com/beautiful-soup-web-scraper-python/). Another framework to consider is [Scrapy](https://scrapy.org/).

### Scraper using Beautiful Soup

```python
import requests
from bs4 import BeautifulSoup

#Visit Page and parse source HTML
page = requests.get("http://www.python.org")
soup = BeautifulSoup(page.content, 'html.parser')

#Check title is as expected
assert "Python" in soup.title.string

##Perform the search using HTTP GET request
page = requests.get("https://www.python.org/search/?q=pip")
soup = BeautifulSoup(page.content, 'html.parser')

#Look for expected result
link = soup.select_one('a:contains("PEP 439")')
#Get the link URL
print (link['href'])
```
